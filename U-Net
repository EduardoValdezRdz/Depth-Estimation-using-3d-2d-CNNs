from __future__ import print_function
from random import shuffle
import glob
import numpy as np
import cv2
import h5py
from PIL import Image
import os
import random
import keras
from keras.utils import multi_gpu_model
from keras import layers
import h5py
from keras.models import Model
from keras.layers import Input, MaxPooling2D, Dropout, Conv2DTranspose, BatchNormalization, Activation
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.merge import concatenate
import threading
from keras.utils import plot_model
import cv2

shuffle_data = True  # shuffle the addresses before saving
images_train_root = '/synthia_new/train/*' #Dataset adress
addrs = glob.glob(images_train_root)

full_data_depth = []
for i in addrs:
    a = i+'/Depth/*.png'
    addrs_depth = glob.glob(a)
    for x in addrs_depth:
        full_data_depth.append(x)

full_data_rgb = []
for i in addrs:
    a = i+'/RGB/*.png'
    addrs_rgb = glob.glob(a)
    for x in addrs_rgb:
        full_data_rgb.append(x)

full_data_seg = []
for i in addrs:
    a = i+'/SemSeg/*.png'
    addrs_seg = glob.glob(a)
    for x in addrs_seg:
        full_data_seg.append(x)

# tamanos de imagen
sia = 192
sib = 320
sta = 192
stb = 320

full_data_depth.sort()
print(len(full_data_depth))

full_data_rgb.sort()
print(len(full_data_rgb))

full_data_seg.sort()
print(len(full_data_seg))

if shuffle_data:
    d = list(zip(full_data_rgb, full_data_seg, full_data_depth))
    shuffle(d)
    full_data_rgb, full_data_seg, full_data_depth = zip(*d)

train_addrscolor = full_data_rgb[0:int(1 * len(full_data_rgb))]
train_addrslabels = full_data_seg[0:int(1 * len(full_data_seg))]
train_addrsdepth = full_data_depth[0:int(1 * len(full_data_depth))]

nclases = 14


def one_hot_it(labels):
    x = np.zeros((sia, sib, nclases))
    for i in range(sia):
        for j in range(sib):
            x[i, j, labels[i][j]] = 1
    return x


"""
Labels

Label	-> Name		->   RGB
---------------------
        0	-> Void		->   0,0,0
        1	-> Road		->   128,64,128
        2	-> Sidewalk	->   244,35,232
        3	-> Building	->   70,70,70
        4	-> Wall		->   102,102,156
        5	-> Fence	->   190,153,153
        6	-> Pole		->   153,153,153
        7	-> Traffic Light->   250,170,30
        8	-> Traffic Sign	->   220,220,0
        9	-> Vegetation	->   107,142,35
        10	-> Terrain	->   152,251,152
        11	-> Sky		->   70,130,180
        12	-> Person	->   220,20,60
        13	-> Rider	->   255,0,0
        14	-> Car		->   0,0,142
        15	-> Truck	->   0,0,70
        16	-> Bus		->   0,60,100
        17	-> Train	->   0,80,100
        18	-> Motorcycle	->   0,0,230
        19	-> Bicycle	->   119,11,32
        20	-> Road Lines	->   157.234,50
        21	-> Other	->   72,0,98
        22	-> Road Works	->   167,106,29
"""


def procesar_etiquetas(ruta_imagen):
    labelt = cv2.imread(ruta_imagen, cv2.IMREAD_UNCHANGED)
    labelt= cv2.resize(labelt, (sib, sia))
    labelt = labelt.astype('int')
    auxtc = np.zeros((sta, stb, 1), 'int')
    auxtc[:, :, 0] = labelt[:, :, 2]
    labeln = np.zeros((sta, stb))
    for l in range(labelt.shape[0]):
        for j in range(labelt.shape[1]):
            #void
            if auxtc[l, j, 0] == 21:
                labeln[l, j] = 0

            elif auxtc[l, j, 0] == 22:
                labeln[l, j] = 0

            elif auxtc[l, j, 0] > 20:
                labeln[l, j] = 0

            #sky
            elif auxtc[l, j, 0] == 11:
                labeln[l, j] = 1

            #building
            elif auxtc[l, j, 0] == 3:
                labeln[l, j] = 2

            elif auxtc[l, j, 0] == 4:
                labeln[l, j] = 2

            #road
            elif auxtc[l, j, 0] == 1:
                labeln[l, j] = 3
            elif auxtc[l, j, 0] == 10:
                labeln[l, j] = 3

            #sidewalk
            elif auxtc[l, j, 0] == 2:
                labeln[l, j] = 4

            #fence
            elif auxtc[l, j, 0] == 5:
                labeln[l, j] = 5

            #vegetation
            elif auxtc[l, j, 0] == 9:
                labeln[l, j] = 6

            #pole
            elif auxtc[l, j, 0] == 6:
                labeln[l, j] = 7

            #vehicle
            elif auxtc[l, j, 0] == 14:
                labeln[l, j] = 8
            elif auxtc[l, j, 0] == 15:
                labeln[l, j] = 8
            elif auxtc[l, j, 0] == 16:
                labeln[l, j] = 8
            elif auxtc[l, j, 0] == 17:
                labeln[l, j] = 8

            #sign
            elif auxtc[l, j, 0] == 8:
                labeln[l, j] = 9

            #pedestrian
            elif auxtc[l, j, 0] == 12:
                labeln[l, j] = 10

            #cyclist
            elif auxtc[l, j, 0] == 13:
                labeln[l, j] = 11
            elif auxtc[l, j, 0] == 18:
                labeln[l, j] = 11
            elif auxtc[l, j, 0] == 19:
                labeln[l, j] = 11

            #lanemrk
            elif auxtc[l, j, 0] == 20:
                labeln[l, j] = 12

            #trafficlight
            elif auxtc[l, j, 0] == 7:
                labeln[l, j] = 13

            else:
                labeln[l, j] = labeln[l, j]

    labeln = labeln.astype('int')
    test = one_hot_it(labeln)
    #cv2.imshow('test', test[:, :, 15])
    onehot = np.transpose(test, (2, 0, 1))
    return onehot


def proceesar_rgb(ruta_rgb):
    imgd = Image.open(ruta_rgb)  # Replace with your image name here
    imgd = np.array(imgd)
    imgd = cv2.resize(imgd, (sib, sia))
    max_val = float(np.iinfo(imgd.dtype).max)
    imgd = imgd/max_val
    imgd = imgd.astype('float32')
    auxd = np.zeros((sia, sib, 3), np.float32)
    auxd[:, :, :] = imgd[:, :, 0:3]
    #cv2.imshow('test1', auxd)
    auxd = np.transpose(auxd, (2, 0, 1))
    return auxd


def generator(image_file_list, labels_file_list, batch_size):
    i = 0
    while True:
        batch = {'images': [], 'labels': []}  # use a dict for multiple inputs
        for b in range(batch_size):
            if i == len(image_file_list):
                i = 0
            sample = image_file_list[i]
            sample2 = labels_file_list[i]
            image_file_path = sample
            image_file_path2 = sample2
            i += 1
            image = proceesar_rgb(image_file_path)
            labels = procesar_etiquetas(image_file_path2)
            batch['images'].append(image)
            batch['labels'].append(labels)
        batch['images'] = np.array(batch['images'])
        batch['labels'] = np.array(batch['labels'])
        yield batch['images'], batch['labels']


data_format = 'channels_first'

input_height = 192
input_width = 320
nClasses = 14


def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal", padding="same", data_format=data_format)(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
        x = Activation("relu")(x)
        # second layer
        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal", padding="same", data_format=data_format)(x)
    if batchnorm:
        x = BatchNormalization()(x)
        x = Activation("relu")(x)
    return x


def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):
    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    p1 = MaxPooling2D((2, 2), data_format=data_format)(c1)
    p1 = Dropout(dropout*0.5)(p1)
    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    p2 = MaxPooling2D((2, 2), data_format=data_format)(c2)
    p2 = Dropout(dropout)(p2)
    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    p3 = MaxPooling2D((2, 2), data_format=data_format)(c3)
    p3 = Dropout(dropout)(p3)
    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    p4 = MaxPooling2D(pool_size=(2, 2), data_format=data_format)(c4)
    p4 = Dropout(dropout)(p4)
    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)
    # expansive path
    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c5)
    u6 = concatenate([u6, c4], axis=1)
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)
    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c6)
    u7 = concatenate([u7, c3], axis=1)
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)
    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c7)
    u8 = concatenate([u8, c2], axis=1)
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)
    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same', data_format=data_format)(c8)
    u9 = concatenate([u9, c1], axis=1)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)
    outputs = Conv2D(nClasses, (1, 1), activation='sigmoid', data_format=data_format)(c9)
    model = Model(inputs=[input_img], outputs=[outputs])
    return model


inputs = Input((3, input_height, input_width))
model = get_unet(inputs, n_filters=64, dropout=0.05, batchnorm=True)
model = multi_gpu_model(model, gpus=2)
model.compile(optimizer='adam', loss="binary_crossentropy", metrics=["accuracy"])
model.summary()
plot_model(model, to_file='model.png', show_shapes=True)


def data_statistic(train_dataset):
    len(train_dataset)
    return len(train_dataset)


batch_size = 27
train_generator = generator(train_addrscolor, train_addrslabels, batch_size)
nb_train_samples = data_statistic(train_addrscolor)
print('train samples: %d' % nb_train_samples)

model.fit_generator(epochs=3, generator=train_generator, steps_per_epoch=nb_train_samples // batch_size)

model_json = model.to_json()
with open('model16C.json', 'w') as json_file:
    json_file.write(model_json)
model.save_weights('RNA16C.h5')

